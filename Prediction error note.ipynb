{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose $ \\mathbb{R}^n \\ni Y|X \\sim N(\\mu, \\Sigma_t)$ and we fit a (GLS) linear regression model on $X_{n \\times p}$ using quadratic part $\\Theta_e$ yielding $\\hat{\\beta}$\n",
    "$$\n",
    "(X'\\Theta_e^{-1}X)^{-1}X'\\Theta_e^{-1}Y\n",
    "$$\n",
    "\n",
    "We want to evaluate our linear model by providing an estimate of \n",
    "$$\n",
    "E[(Y^*-X\\hat{\\beta})'\\Theta_p(Y^*-X\\hat{\\beta})|X]\n",
    "$$\n",
    "where $Y^*|X \\sim N(\\mu,\\Sigma_t)$ and is conditionally independent of $Y$ given $X$.\n",
    "\n",
    "## Mallow's $C_p$\n",
    "\n",
    "In the Mallow's case we have $\\Sigma_t= I, \\Theta_e=\\Theta_p=I$ but we could consider others.\n",
    "\n",
    "The naming of the $\\Theta / \\Sigma$'s are to denote covariaince and precision matrices as well as to denote which task: $e$  (estimation); $t$ (truth); $p$  (prediction).\n",
    "\n",
    "Here we note that\n",
    "$$\n",
    "\\|Y^*-X\\hat{\\beta}\\|^2_2 = \\|Y^*-P_IY\\|^2_2 = \n",
    "\\|Y^*-P_IY^*\\|^2_2 + \\|P_I(Y^*-Y)\\|^2_2.\n",
    "$$\n",
    "\n",
    "We're using the notation\n",
    "$$\n",
    "P_{Q}Y = X(X'QX)^{-1}X'QY\n",
    "$$\n",
    "and we note that $Y-P_{\\Theta_t}Y$ is independent of $P_{\\Theta_t}Y$. Note that $P_Q$ is not a projection matrix in general, i.e. it is not symmetric and idemptotent. It is\n",
    "effectively the smoothing matrix for GLS regression using precision $Q$.\n",
    "\n",
    "In this case $E[\\|Y^*-P_IY^*\\|^2_2|X]=E[\\|Y-P_IY\\|^2_2|X]$ and $E[\\|P_I(Y^*-Y)\\|^2_2|X]=2 \\text{Tr}(P_I)$ as $E[P_I(Y-Y^*)|X]=0$.\n",
    "\n",
    "This leads to the (conditionally) unbiased (given $X$) estimator\n",
    "$$\n",
    "\\|Y-P_IY\\|^2_2 + 2 p \\sigma^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slightly more general\n",
    "\n",
    "Let's assume $\\Theta_e=\\Theta_p=I$ but $\\Sigma_t$ is generally different. \n",
    "Here\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\|Y^*-P_IY\\|^2_2  \n",
    "&= \\|Y^*-Y+Y-P_{I}Y\\|^2_2 \\\\\n",
    "&= \\|Y^*-Y\\|^2_2 + 2(Y^*-Y)'(Y-P_{I}Y) + \\|Y-P_{I}Y\\|^2_2 \\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, \n",
    "$$\n",
    "E[\\|Y^*-Y\\|^2_2|X] = 2 \\text{Tr}(\\Sigma_t)\n",
    "$$\n",
    "Also\n",
    "$$\n",
    "E[(Y^*-Y)'(Y-P_{I}Y)|X] = -E[(Y-\\mu)'(I-P_{I})(Y-\\mu)|X]\n",
    "= - \\text{Tr}(\\Sigma_t(I-P_{I}))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting this together I think yields the conditionally unbiased estimator\n",
    "$$\n",
    "2 \\text{Tr}(\\Sigma_t) - 2 \\text{Tr}(\\Sigma_t(I-P_{I})) + \\|Y-P_{I}Y\\|^2_2 =\n",
    "\\|Y-P_IY\\|^2_2 + 2 \\text{Tr}(\\Sigma_tP_I)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When $\\Sigma_t= \\sigma^2 \\cdot I$ we recover Mallow's estimate of course. \n",
    "\n",
    "We can take $\\Theta_e$ to be arbitrary (no where did we use the fact that $\\Theta_e=I$ above except to write $P_I$. This yields an unbiased estimate\n",
    "$$\n",
    "\\|Y-P_{\\Sigma_e}Y\\|^2_2 + 2 \\text{Tr}(\\Sigma_tP_{\\Sigma_e})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last step\n",
    "\n",
    "By setting $\\Theta_p$ to be arbitrary we cover all bases. \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "(Y^*-P_{\\Theta_e}Y)'\\Theta_p(Y^*-P_{\\Theta_e}Y)\n",
    "&= \n",
    "(Y^*-Y+Y-P_{\\Theta_e}Y)'\\Theta_p(Y^*-Y+Y-P_{\\Theta_e}Y) \\\\\n",
    "&= (Y^*-Y)\\Theta_p(Y^*-Y) + 2(Y^*-Y)'\\Theta_p(Y-P_{\\Sigma_e}Y) \\\\\n",
    "& \\qquad + (Y-P_{\\Theta_e}Y)'\\Theta_p(Y-P_{\\Theta_e}Y)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Yields a condtionally unbiased estimator of the form\n",
    "$$\n",
    "2 \\text{Tr}(\\Sigma_t\\Theta_p - 2 \\text{Tr}(\\Theta_p\\Sigma_t(I-P_{\\Theta_e})) + (Y-P_{\\Theta_e}Y)'\\Theta_p(Y-P_{\\Theta_e}Y) = 2 \\text{Tr}(\\Theta_p\\Sigma_tP_{\\Theta_e}) + (Y-P_{\\Theta_e}Y)'\\Theta_p(Y-P_{\\Theta_e}Y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out of sample prediction\n",
    "\n",
    "Suppose we want to estimate the MSE on some subset of the points after having fit on another. Call the training subset ${\\cal T}$ and the\n",
    "remaining ${\\cal T}^c$ and let $S_{\\cal T}:\\mathbb{R}^n \\rightarrow \\mathbb{R}^{\\cal T} = I[{\\cal T}]$ denote the selector for the training data.\n",
    "\n",
    "This can be accomplished e.g. using \n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\Theta_e &= S_{\\cal T}'S_{\\cal T} \\\\\n",
    "\\Theta_p &= I - \\Theta_e = S_{{\\cal T}^c}'S_{{\\cal T}^c}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "This doesn't capture variability of $X$ (all variation here is considered condtional on $X$) which corresponds to the union of the test and training $X$'s.\n",
    "\n",
    "## Affine estimators\n",
    "\n",
    "Suppose we generalize our estimators to affine estimators\n",
    "$$\n",
    "\\hat{Y} = P_{\\Theta_e}Y + \\alpha_e.\n",
    "$$\n",
    "\n",
    "Well,\n",
    "$$\n",
    "\\begin{aligned}\n",
    "(Y^*-P_{\\Theta_e}Y-\\alpha_e)'\\Theta_p(Y^*-P_{\\Theta_e}Y-\\alpha_e)\n",
    "&= \n",
    "(Y^*-Y+Y-P_{\\Theta_e}Y)'\\Theta_p(Y^*-Y+Y-P_{\\Theta_e}Y) \\\\\n",
    "&= (Y^*-Y)\\Theta_p(Y^*-Y) + 2(Y^*-Y)'\\Theta_p(Y-P_{\\Sigma_e}Y-\\alpha_e) \\\\\n",
    "& \\qquad + (Y-P_{\\Theta_e}Y-\\alpha_e)'\\Theta_p(Y-P_{\\Theta_e}Y-\\alpha_e)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Again,\n",
    "$$\n",
    "E[(Y^*-Y)'(Y-P_{\\Theta_e}Y-\\alpha_e)|X] = -E[(Y-\\mu)'(I-P_{\\Theta_e})(Y-\\mu)|X]\n",
    "= - \\text{Tr}(\\Sigma_t(I-P_{\\Theta_e})).\n",
    "$$\n",
    "\n",
    "Yields a condtionally unbiased estimator\n",
    "$$\n",
    "2 \\text{Tr}(\\Theta_p\\Sigma_tP_{\\Theta_e}) + (Y-P_{\\Theta_e}Y-\\alpha_e)'\\Theta_p(Y-P_{\\Theta_e}Y-\\alpha_e)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weaking $(Y,Y^*)$ assumption\n",
    "\n",
    "We really only used two properties of $Y^*$ above: $E[Y^*-Y|X]=0$ and in computing\n",
    "$$\n",
    "E[(Y^*-Y)'\\Theta_p(Y-P_{I}Y)|X] = -E[(Y-\\mu)'\\Theta_p(I-P_{I})(Y-\\mu)|X]\n",
    "= - \\text{Tr}(\\Sigma_t\\Theta_p(I-P_{I})).\n",
    "$$\n",
    "\n",
    "The first property gets at the notion\n",
    "of having some sort of idealized replicate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "Y \\\\\n",
    "Y^*\n",
    "\\end{pmatrix} \\sim N \\left(\\begin{pmatrix}\n",
    "\\mu \\\\\n",
    "\\mu\n",
    "\\end{pmatrix},\n",
    "\\begin{pmatrix}\n",
    "\\Sigma_{t}[Y,Y] & \\Sigma_t[Y,Y^*] \\\\\n",
    "\\Sigma_t[Y^*,Y] & \\Sigma_t[Y^*,Y^*]\n",
    "\\end{pmatrix}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "With this notation\n",
    "$$\n",
    "E[(Y-Y^*)'\\Theta_p(Y-Y^*)'|X] = \\text{Tr}\\left(\\Theta_p \\left(\\Sigma_{t}[Y,Y] - 2 \\Sigma_{t}[Y,Y^*] + \\Sigma_{t}[Y^*,Y^*]\\right)\\right)\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\begin{aligned}\n",
    "E[(Y^*-Y)'\\Theta_p(Y-P_{I}Y)|X] &= -E[(Y-\\mu-(Y^*-\\mu))'\\Theta_p(I-P_{I})(Y-\\mu)|X] \\\\\n",
    "&= - \\text{Tr}((\\Sigma_t[Y,Y]-\\Sigma_t[Y^*,Y])\\Theta_p(I-P_{I})) \\\\\n",
    "&= \\text{Tr}((\\Sigma_t[Y,Y]-\\Sigma_t[Y^*,Y])\\Theta_p P_I) - \\text{Tr}(\\Sigma_t[Y,Y]\\Theta_p) + \\text{Tr}(\\Sigma_t[Y^*,Y]\\Theta_p)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting these together yields a conditionally unbiased estimator\n",
    "$$\n",
    "2 \\text{Tr}((\\Sigma_t[Y,Y]-\\Sigma_t[Y^*,Y])\n",
    "\\Theta_p P_{\\Theta_e}) +  \n",
    "\\text{Tr}(\\Theta_p(\\Sigma_t[Y^*,Y^*] - \\Sigma_t[Y,Y])) + (Y-P_{\\Theta_e}Y-\\alpha_e)'\\Theta_p(Y-P_{\\Theta_e}Y-\\alpha_e)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomization\n",
    "\n",
    "Below we will consider picking an affine estimator based on a randomized\n",
    "version of $Y$. To not use $Y$ too often, we will denote a randomized version by $W$. Given some randomization covariance $\\Sigma_{\\epsilon}$ (which we take wlog to be non-singular) we define\n",
    "$$\n",
    "W = Y + \\epsilon, \\qquad \\epsilon | Y , Y^*, X \\sim N(0, \\Sigma_{\\epsilon}).\n",
    "$$\n",
    "\n",
    "There is a corresponding randomization of $Y$ that has the same mean as $Y|X$ (and $W|X$) but is (conditionally) independent of $W$ given $X$:\n",
    "$$\n",
    "W^{\\perp} = Y - \\Sigma_t \\Sigma^{-1}_{\\epsilon} \\epsilon.\n",
    "$$\n",
    "\n",
    "The original $Y$ can be reconstructed from $W, W^{\\perp}$ as\n",
    "$$\n",
    "AW+A^{\\perp}W^{\\perp}\n",
    "$$\n",
    "with\n",
    "$$\n",
    "\\begin{aligned}\n",
    "A^{\\perp} &= (I+\\Sigma_t\\Sigma_{\\epsilon}^{-1})^{-1} \\\\\n",
    "A &= I - A^{\\perp}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Our estimators will be of the form (*full refit*)\n",
    "$$\n",
    "\\hat{Y}(Y,W) = P(W)Y+\\alpha(W).\n",
    "$$\n",
    "In words, we use $W$ to find some linear model with offset and refit that model to the original $Y$. We can also consider\n",
    "non-refit estimators\n",
    "$$\n",
    "\\hat{Y}_n(Y,W) = P(W)W+\\alpha(W).\n",
    "$$\n",
    "If we construct a third randomized $W$ (e.g. by splitting $W$ into $W_0,W_1$ we could also\n",
    "look at \"honest\" refit estimators\n",
    "$$\n",
    "\\hat{Y}_h(Y,W_0,W_1) = P(W_0)W_1+\\alpha(W_0)\n",
    "$$\n",
    "where we maintain the $\\text{Cov}(W_0,W^{\\perp}|X) =\\text{Cov}(W_1,W^{\\perp}|X)=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1: $\\Sigma_t[Y,Y^*]=0$, full refit\n",
    "\n",
    "This is the closest analog to [Tian](https://projecteuclid.org/journals/annals-of-statistics/volume-48/issue-2/Prediction-error-after-model-search/10.1214/19-AOS1818.full).\n",
    "\n",
    "We note that\n",
    "\n",
    "$$\n",
    "E[(Y^*-PY-\\alpha)'\\Theta_p(Y^*-PY-\\alpha)|(P(W),\\alpha(W))=(P,\\alpha), X] = \\text{Tr}(\\Sigma_t[Y^*,Y^*]\\Theta_p) +\n",
    "E[(\\mu-PY-\\alpha)'\\Theta_p(\\mu-PY-\\alpha)|(P(W),\\alpha(W))=(P,\\alpha), X].\n",
    "$$\n",
    "\n",
    "Now consider\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&E[(W^{\\perp}-PY-\\alpha)'\\Theta_p(W^{\\perp}-PY-\\alpha)|(P(W),\\alpha(W))=(P,\\alpha), X] \\\\\n",
    "= &E[(\\mu-PY-\\alpha)'\\Theta_p(\\mu-PY-\\alpha)|(P(W),\\alpha(W))=(P,\\alpha), X] + E[(W^{\\perp}-\\mu)'\\Theta_p(W^{\\perp}-\\mu)]\n",
    "+ 2 E[(W^{\\perp}-\\mu)'\\Theta_p(\\mu-PY-\\alpha) | (P(W),\\alpha(W))=(P,\\alpha), X] \\\\\n",
    "= &E[(\\mu-PY-\\alpha)'\\Theta_p(\\mu-PY-\\alpha)|(P(W),\\alpha(W))=(P,\\alpha), X] + \\text{Tr}(\\text{Cov}(W^{\\perp})\\Theta_p)\n",
    "- 2 E[(W^{\\perp}-\\mu)'\\Theta_pPY | (P(W),\\alpha(W))=(P,\\alpha), X] \\\\\n",
    "= &E[(\\mu-PY-\\alpha)'\\Theta_p(\\mu-PY-\\alpha)|(P(W),\\alpha(W))=(P,\\alpha), X] + \\text{Tr}(\\text{Cov}(W^{\\perp})\\Theta_p)\n",
    "- 2 E[(W^{\\perp}-\\mu)'\\Theta_pPA^{\\perp}W^{\\perp} | (P(W),\\alpha(W))=(P,\\alpha), X] \\\\\n",
    "= &E[(\\mu-PY-\\alpha)'\\Theta_p(\\mu-PY-\\alpha)|(P(W),\\alpha(W))=(P,\\alpha), X] + \\text{Tr}(\\text{Cov}(W^{\\perp})\\Theta_p)\n",
    "- 2 \\text{Tr}\\left(\\text{Cov}(W^{\\perp}\\Theta_p P\\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "This yields a conditionally unbiased estimator (given $X$)\n",
    "$$\n",
    "(W^{\\perp}-P(W)Y-\\alpha(W))'\\Theta_p(W^{\\perp}-P(W)Y-\\alpha(W)) + \\text{Tr}(\\Sigma_t[Y^*,Y^*]\\Theta_p) - \\text{Tr}(\\text{Cov}(W^{\\perp})\\Theta_p)\n",
    " + 2 \\text{Tr}\\left(\\text{Cov}(W^{\\perp}\\Theta_p P(W)\\right)\n",
    "$$\n",
    "with\n",
    "$$\n",
    "\\text{Cov}(W^{\\perp}) = \\Sigma_t + \\Sigma_t\\Sigma_{\\epsilon}^{-1}\\Sigma_t\n",
    "$$\n",
    "\n",
    "### Different refits\n",
    "\n",
    "The honest and non-honest refits yield even simpler forms because $W^{\\perp}$ is (conditionally) independent of both $W_0,W_1$ (given $X$). This means there is no need for the last term in the unbiased estimator.\n",
    "\n",
    "### Allowing for $\\Sigma_t[Y,Y^*] \\neq 0$.\n",
    "\n",
    "**This is a bit puzzling for the moment (and Xiaoying didn't consider this). Don't know how interesting it is.**\n",
    "\n",
    "## Bagged version\n",
    "\n",
    "Let's call our randomized risk estimator $RRisk(\\Sigma_t,\\Theta_p,Y,X,W,W^{\\perp},\\text{selector})$\n",
    "where $\\text{selector}(W) = (P(W), \\alpha(W))$ is the mechanism by which we choose\n",
    "the next affine estimator.\n",
    "\n",
    "Suppose we draw $K$ $(W,W')$ pairs given $Y,X$, we might want to have an estimate of\n",
    "$$\n",
    "E\\left[\\left\\|Y^*-\\frac{1}{K}\\sum_{k=1}^K[P(W_k)Y + \\alpha(W_k)]\\right\\|^2_2\\biggl| X \\right].\n",
    "$$\n",
    "\n",
    "Well, using $\\Theta_p=I$\n",
    "$$\n",
    "E \\left[RRisk(Y,X,W_k^{\\perp},W_k)\\biggl| X \\right]\n",
    "= E\\left[\\left\\|Y^*-[P(W_k)Y + \\alpha(W_k)]\\right\\|^2_2\\biggl| X \\right].\n",
    "$$\n",
    "\n",
    "Let's collect the vectors $Y^*-P(W_k)Y-\\alpha(W_k)$ into an $n \\times K$ matrix $Z_K$ and set $\\bar{Z}_K$ to be the row means of $Z_K$\n",
    "Summing random variable over $k$ on the RHS yields\n",
    "$$\n",
    "\\text{Tr}(Z_K'Z_K) = \\frac{1}{K}\\text{Tr}(11'Z_K'Z_K) + \\text{Tr}((I_K-K^{-1}11')Z_K((I_K-K^{-1}11')Z_K))'\n",
    "$$\n",
    "The first term (up to scaling by $K^{-1}$) is the quantity whose mean (given $X$) we'd like to estimate.\n",
    "AND the matrix $Z^{\\perp}_K = (I-K^{-1}11')Z_K$ has columns which are the elementwise residuals\n",
    "after centering each row, i.e.\n",
    "$$\n",
    "-P(W_k)Y-\\alpha(W_k) + \\frac{1}{K}\\sum_{l=1}^K(P(W_l)Y+\\alpha(W_l))\n",
    "$$\n",
    "**This matrix is observable and we have (conditionally) unbiased (given $X$) estimator for expectation of $\\text{Tr}(Z_K'Z_K)$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
